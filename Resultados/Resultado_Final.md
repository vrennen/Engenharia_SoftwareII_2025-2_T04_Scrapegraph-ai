# üèÅ Veredito da An√°lise: Vencedores e Perdedores

Este documento cruza os resultados dos tr√™s modelos de IA com nossa **valida√ß√£o manual (gabarito)** para determinar quais modelos foram eficazes na identifica√ß√£o da arquitetura do `Scrapegraph-ai`.

Nossa an√°lise manual do c√≥digo-fonte estabeleceu que a arquitetura √©, inequivocamente, **Pipe and Filter**, baseada na estrutura de pastas `/nodes` (Filtros) e `/graphs` (Pipelines).

## üèÜ Os Vencedores (An√°lise de C√≥digo-Fonte)

Os dois modelos que analisaram o **c√≥digo-fonte (`.py`)** foram aprovados com sucesso, cada um validando o nosso gabarito de uma forma diferente.

### ü•á Vencedor Quantitativo: `microsoft/unixcoder-base`

Este modelo foi o mais eficaz para determinar o padr√£o dominante.

* **Por que Venceu:** O modelo analisou 171 arquivos de c√≥digo e deu uma vit√≥ria **esmagadora e decisiva** para o padr√£o correto. O resultado de **138 votos para "Pipe and Filter"** (contra 20 do segundo colocado) n√£o deixa d√∫vidas. Ele ignorou o "ru√≠do" da documenta√ß√£o e identificou corretamente a sem√¢ntica do c√≥digo nas pastas `/examples`, `/graphs` e `/nodes`.

* **Ressalvas (Limita√ß√µes):** Embora tenha vencido, este modelo **falhou em 38 arquivos**. Ele gerou um erro de `index out of range` em muitos dos arquivos-chave da arquitetura (como `abstract_graph.py` e `fetch_node.py`). Isso indica um bug no tokenizer do modelo, mas, felizmente, os 171 arquivos que ele *conseguiu* analisar foram suficientes para dar a resposta correta.

### üèÖ Vencedor Qualitativo: `t5-small`

Este modelo forneceu a **prova confirmat√≥ria**, explicando *por que* o Modelo 2 estava certo.

* **Por que Venceu:** Ele n√£o foi for√ßado a "votar", mas sim a "descrever" o c√≥digo. Suas descri√ß√µes dos arquivos-chave (pastas `/nodes` e `/graphs`) usaram a terminologia exata do padr√£o Pipe and Filter.
    * Ele descreveu os arquivos `/graphs` como "scraping **pipeline**" (18 vezes).
    * Ele descreveu os arquivos `/nodes` como "**node**" (29 vezes) e "graph" (33 vezes), confirmando a estrutura que encontramos manualmente.

---

## üëé O Perdedor (An√°lise de Documenta√ß√£o)

### ü•â Perdedor: `facebook/bart-large-mnli`

Este modelo, focado em documenta√ß√£o, falhou completamente em identificar o padr√£o.

* **Por que Perdeu:** O resultado foi um **empate t√©cnico inconclusivo** (9 votos para Layered, 9 para Pipe/Filter, 8 para Microservices). O modelo foi "envenenado" pela ambiguidade da linguagem humana nos arquivos `.md`.
    * Ele viu palavras como "API" ou "servi√ßo" (referindo-se ao OpenAI) e votou em **Microservices**.
    * Ele viu palavras como "m√≥dulo", "documenta√ß√£o", "contribui√ß√£o" e votou em **Layered Architecture**.
    * Ele n√£o teve a capacidade de distinguir a arquitetura principal dos conceitos relacionados mencionados no texto.

---

## üèÅ Conclus√£o Final: C√≥digo-Fonte √© a Fonte da Verdade

A li√ß√£o desta atividade √© clara: para a an√°lise de arquitetura de software, **o c√≥digo-fonte √© uma fonte de verdade muito mais confi√°vel do que a documenta√ß√£o**.

Os modelos treinados para c√≥digo (`unixcoder-base` e `t5-small`) foram altamente eficazes e precisos, alinhando-se 100% com nossa valida√ß√£o manual. O modelo treinado para texto (`bart-large-mnli`) falhou por n√£o conseguir lidar com a ambiguidade do texto comum.