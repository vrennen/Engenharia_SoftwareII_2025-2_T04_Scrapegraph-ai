# üöÄ Atividade 1: An√°lise de Padr√µes Arquiteturais com LLMs
**Reposit√≥rio da Atividade:** `Engenharia_SoftwareII_2025-2_T04_Scrapegraph-ai`

## üë• Componentes da Equipe

| Nome | Matr√≠cula | Contribui√ß√£o |
| :--- | :--- | :--- |
| Maria Eduarda M. da Silva | 202300038860 | Documenta√ß√£o, Valida√ß√£o Manual e Scripts |
| Rafael Gomes Oliveira Santos | 202300095730 | Documenta√ß√£o, Valida√ß√£o Manual e Scripts |
| Cauan Teixeira Machado | 202300038627 | An√°lise com Modelo 1 (facebook/bart-large-mnli) |
| Pedro Joaquim Silva Silveira | 202300038897 | An√°lise com Modelo 1 (facebook/bart-large-mnli) |
| Breno Silva do Nascimento | 202300038968 | An√°lise com Modelo 2 (microsoft/unixcoder-base) |
| Jos√© Gabriel R. G. de Almeida | 202300095599 | An√°lise com Modelo 2 (microsoft/unixcoder-base) |
| Jos√© Victor Ribeiro de Jesus | 202300038799 | An√°lise com Modelo 3 (t5-small) |
| Mateus da Silva Barreto | 202300038879 | An√°lise com Modelo 3 (t5-small) |

---

## üéØ 1. Vis√£o Geral do Projeto

Este projeto cumpre os requisitos da Atividade 1 da disciplina de Engenharia de Software II. O objetivo foi analisar o reposit√≥rio open-source **`Scrapegraph-ai`** (`https://github.com/ScrapeGraphAI/Scrapegraph-ai`) para identificar seus padr√µes arquiteturais de software.

Para isso, utilizamos tr√™s Modelos de Linguagem (LLMs) distintos da plataforma Hugging Face, com tr√™s estrat√©gias de an√°lise diferentes:

1.  **An√°lise de Documenta√ß√£o (Texto):** Classifica√ß√£o de arquivos `.md` para entender a *inten√ß√£o* da arquitetura.
2.  **An√°lise de C√≥digo (Quantitativa):** Classifica√ß√£o vetorial de arquivos `.py` para identificar o padr√£o de c√≥digo *dominante*.
3.  **An√°lise de C√≥digo (Qualitativa):** Sumariza√ß√£o de arquivos `.py` chave para *validar* as descobertas.

A an√°lise conclusiva, baseada nos modelos de c√≥digo, determinou que o `Scrapegraph-ai` √© predominantemente implementado usando o padr√£o **Pipe and Filter**.

---

## üõ†Ô∏è 2. Tutorial de Execu√ß√£o e Replicabilidade

Este tutorial detalha o passo a passo para configurar o ambiente e executar os tr√™s scripts de an√°lise que produzem os logs de resultado.

### 2.1. Estrutura de Pastas

Para que os scripts funcionem, a estrutura de pastas do projeto **deve** ser a seguinte: 

üìÅ [Pasta Raiz do Projeto] ‚îÇ ‚îú‚îÄ‚îÄ üìÅ Scrapegraph-ai\ (O reposit√≥rio clonado) ‚îÇ ‚îú‚îÄ‚îÄ üìÅ venv\ (O ambiente virtual Python) ‚îÇ ‚îú‚îÄ‚îÄ üìú analise_documentacao.py (Script do Modelo 1) ‚îú‚îÄ‚îÄ üìú analise_codigo_alternativa.py (Script do Modelo 2) ‚îî‚îÄ‚îÄ üìú analise_sumarizacao_FINAL.py (Script do Modelo 3)

### 2.2. Configura√ß√£o do Ambiente

1.  **Clonar o Reposit√≥rio Alvo:** Na pasta raiz do seu projeto, clone o `Scrapegraph-ai`:
    ```bash
    git clone https://github.com/ScrapeGraphAI/Scrapegraph-ai.git
    ```

2.  **Criar o Ambiente Virtual:**
    ```bash
    python -m venv venv
    ```

3.  **Ativar o Ambiente Virtual:**
    * **Windows:** `.\venv\Scripts\activate`
    * **macOS/Linux:** `source venv/bin/activate`

4.  **Instalar Bibliotecas:** Com o `(venv)` ativo, instale todas as depend√™ncias necess√°rias:
    ```bash
    python -m pip install transformers torch sentence-transformers scikit-learn sentencepiece
    ```
    > **Nota:** Se a instala√ß√£o do `torch` falhar no Windows com um erro de "Caminho Longo" (OSError), voc√™ deve habilitar o Suporte a Caminhos Longos no Windows e reiniciar o computador antes de tentar novamente.

---

## ‚öôÔ∏è 3. Execu√ß√£o e Resultados dos Modelos

Abaixo est√£o os comandos para executar cada script e os resultados detalhados de cada an√°lise.

### Modelo 1: An√°lise de Documenta√ß√£o (Classifica√ß√£o de Texto)

Este script varre o reposit√≥rio em busca de arquivos `.md` e os classifica em um dos quatro padr√µes.

* **Modelo:** `facebook/bart-large-mnli`
* **Script:** `analise_documentacao.py`
* **O que faz:** L√™ cada arquivo `.md`, usa o pipeline de "Zero-Shot Classification" para classificar o texto e conta os "votos" para cada padr√£o.
* **Comando de Execu√ß√£o:**
    ```bash
    python analise_documentacao.py
    ```
* **Arquivo de Sa√≠da:** `resultados_analise.txt`

#### 3.1.1. Resultado Detalhado (Modelo 1)

A an√°lise dos 28 arquivos `.md` relevantes resultou em um **empate t√©cnico**:

* **Layered Architecture (MVC or similar):** 9 arquivo(s)
* **Pipe and Filter / Pipeline Architecture:** 9 arquivo(s)
* **Microservices Architecture:** 8 arquivo(s)
* **Monolithic Application:** 2 arquivo(s)

**Conclus√£o (Inconclusivo):** Este modelo se mostrou **pouco confi√°vel**. A documenta√ß√£o usa termos amb√≠guos (como "API", "m√≥dulo", "servi√ßo") que confundiram o classificador, fazendo-o ver padr√µes de Microservi√ßos e Camadas onde eles n√£o eram o foco principal.

### Modelo 2: An√°lise de C√≥digo (Classifica√ß√£o Vetorial)

Este script analisa o c√≥digo-fonte (`.py`) para desempatar a an√°lise anterior, usando similaridade de vetores.

* **Modelo:** `microsoft/unixcoder-base`
* **Script:** `analise_codigo_alternativa.py`
* **O que faz:** Define 4 "prot√≥tipos" (descri√ß√µes) de padr√µes. Transforma cada arquivo `.py` e cada prot√≥tipo em um vetor (embedding). Compara a similaridade de cosseno entre o c√≥digo e os prot√≥tipos, e vota no padr√£o mais "pr√≥ximo".
* **Comando de Execu√ß√£o:**
    ```bash
    python analise_codigo_alternativa.py
    ```
* **Arquivo de Sa√≠da:** `resultados_analise_CODIGO_Unixcoder.txt`

#### 3.1.2. Resultado Detalhado (Modelo 2)

A an√°lise de 171 arquivos `.py` v√°lidos foi **decisiva e esmagadora**:

* **Pipe and Filter:** 138 arquivo(s)
* **Microservices:** 20 arquivo(s)
* **Monolithic:** 10 arquivo(s)
* **Layered / MVC:** 3 arquivo(s)

**Conclus√£o (Decisivo):** Este modelo foi **altamente efetivo**. Ao analisar o c√≥digo-fonte, ele ignorou a ambiguidade da documenta√ß√£o e identificou corretamente que a vasta maioria dos arquivos (exemplos, grafos e n√≥s) implementa o padr√£o **Pipe and Filter**.

### Modelo 3: An√°lise de C√≥digo (Sumariza√ß√£o)

Este script valida a descoberta do Modelo 2, pedindo a um modelo de sumariza√ß√£o que *descreva* os arquivos mais importantes nas pastas `/graphs` e `/nodes`.

* **Modelo:** `t5-small`
* **Script:** `analise_SUMARIZACAO_T5.py`
* **O que faz:** Varre as pastas cruciais (`/graphs` e `/nodes`) e usa o modelo `t5-small` para gerar um resumo em ingl√™s de cada arquivo `.py` encontrado. Em seguida, analisa a frequ√™ncia de termos arquiteturais nos resumos.
* **Comando de Execu√ß√£o:**
    ```bash
    python analise_sumarizacao_FINAL.py
    ```
* **Arquivo de Sa√≠da:** `resultados_analise_SUMARIZACAO_T5.txt`

#### 3.1.3. Resultado Detalhado (Modelo 3)

O script analisou 57 arquivos e gerou os seguintes dados:

* **Termo 'graph' (grafo):** Encontrado em 33 resumos.
* **Termo 'node' (n√≥):** Encontrado em 29 resumos.
* **Termo 'pipeline':** Encontrado em 18 resumos.

O modelo descreveu consistentemente a arquitetura:
* **Arquivos em `/graphs`:** Foram descritos como "scraping **pipeline**" (ex: `smart_scraper_graph.py`).
* **Arquivos em `/nodes`:** Foram descritos como "**node** responsible for fetching/parsing" (ex: `fetch_node.py`, `parse_node.py`).

**Conclus√£o (Confirmat√≥rio):** Este modelo foi **altamente efetivo**. Ele validou a arquitetura **Pipe and Filter** n√£o apenas pela presen√ßa das palavras-chave, mas pela descri√ß√£o funcional correta dos componentes (N√≥s como unidades de processamento e Grafos como pipelines de orquestra√ß√£o).

---

## üìä 4. Compara√ß√£o e Avalia√ß√£o

### 4.1. Tabela Comparativa dos Modelos

| Modelo | Tarefa de NLP | Alvo da An√°lise | Resultado da Identifica√ß√£o | Efetividade |
| :--- | :--- | :--- | :--- | :--- |
| `facebook/bart-large-mnli` | Classifica√ß√£o (Zero-Shot) | Arquivos de Documenta√ß√£o (`.md`) | **Inconclusivo.** Empate t√©cnico (9-9-8) entre Camadas, Pipe/Filter e Microservi√ßos. | **Baixa** |
| `microsoft/unixcoder-base` | Similaridade de Vetores (Embedding) | C√≥digo-Fonte (`.py`) | **Decisivo.** Vit√≥ria esmagadora (138 votos) para **Pipe and Filter**. | **Alta** |
| `t5-small` | Sumariza√ß√£o | C√≥digo-Fonte (Arquivos-Chave) | **Confirmat√≥rio.** Identificou os termos "**graph**" (33x), "**node**" (29x) e "**pipeline**" (18x). | **Alta** |

### 4.2. Avalia√ß√£o de Efetividade (Justificativa)

Conforme a tabela acima, os modelos de an√°lise de c√≥digo-fonte foram **significativamente mais efetivos** do que o modelo de an√°lise de texto.

* **Menos Efetivo:** O `facebook/bart-large-mnli` (Modelo 1) foi o menos efetivo. Sua an√°lise da documenta√ß√£o foi "envenenada" pela ambiguidade da linguagem humana. Termos como "servi√ßo" (referindo-se √† API do OpenAI) e "m√≥dulo" (referindo-se a arquivos Python) o levaram a classificar erroneamente os arquivos como Microservi√ßos ou Camadas.
* **Mais Efetivos:** O `microsoft/unixcoder-base` (Modelo 2) foi o mais efetivo para uma identifica√ß√£o *quantitativa*. Ao analisar o c√≥digo-fonte, ele foi capaz de determinar qual padr√£o era de fato o mais implementado, resolvendo o empate. O `t5-small` (Modelo 3) foi o complemento perfeito, fornecendo valida√ß√£o *qualitativa* ao descrever a arquitetura exatamente como ela √©: uma cole√ß√£o de **Pipelines (Grafos)** e **Filtros (N√≥s)**.